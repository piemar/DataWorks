# ğŸš€ DataWorks

**Enterprise Data Migration & Generation Framework**

---

## ğŸ¯ What is DataWorks?

DataWorks is a professional-grade framework designed for large-scale NoSQL database migrations and data generation. It handles migrations that existing tools simply cannot support.

### ğŸ¯ **Core Capabilities:**

- **ğŸ”„ Large-Scale Migrations**: Handles 100GB+ datasets with enterprise reliability
- **ğŸ“Š Multi-Database Support**: MongoDB Atlas, CosmosDB, DynamoDB, DocumentDB
- **âš¡ High Performance**: Up to 40,000+ documents/second generation, 4,000-8,000 docs/s migration
- **ğŸ›¡ï¸ Enterprise Ready**: Checkpoint recovery, real-time monitoring, error handling
- **ğŸ”§ Flexible Architecture**: Custom generators, migration strategies, JSON templates

### ğŸ†š **Why DataWorks vs Existing Tools?**

| Tool | Large Datasets | Resumable | Real-time Progress | Custom Logic |
|------|----------------|-----------|-------------------|--------------|
| **Compass** | âŒ | âŒ | âŒ | âŒ |
| **mongorestore** | âŒ | âŒ | âŒ | âŒ |
| **mongodump** | âŒ | âŒ | âŒ | âŒ |
| **mongoexport/import** | âŒ | âŒ | âŒ | âŒ |
| **LiveMirror** | âŒ | âŒ | âŒ | âŒ |
| **ğŸš€ DataWorks** | âœ… 100GB+ | âœ… | âœ… | âœ… |

---

## ğŸš€ Quick Start (5 minutes)

### 1. Install DataWorks

```bash
# Clone and setup
git clone https://github.com/piemar/data-migrator.git
cd data-migrator
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Configure Your Databases

```bash
# Copy configuration template
cp .env_local.example .env_local

# Edit with your connection strings
nano .env_local
```

**Required settings in `.env_local`:**
```env
# Choose your profile
FRAMEWORK_PROFILE=data-migration

# Source database (where your data is)
GEN_DB_CONNECTION_STRING="mongodb://your-cosmos-connection-string"
GEN_DB_NAME=your-source-database
GEN_DB_COLLECTION=your-collection

# Target database (where you want to migrate)
MIG_TARGET_DB_CONNECTION_STRING="mongodb+srv://your-atlas-connection-string"
MIG_TARGET_DB_NAME=your-target-database
MIG_TARGET_DB_COLLECTION=your-collection
```

### 3. Test Data Generation

```bash
# Generate 5 test documents
python flexible_generator.py --source user_defined/templates/service_orders/service_order_template.json --total 5
```

**Expected Output:**
```
ğŸš€ Generating custom data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.00/5.00 [00:01<00:00, 3.2docs/s]
ğŸ‰ Data generation completed!
ğŸ“Š Final Results:
   â€¢ Documents generated: 5
   â€¢ Average rate: 32 docs/s
   â€¢ Schema version: 1.0.9282
```

### 4. Run Migration

```bash
# Migrate your data
python flexible_migrate.py --strategy user_defined/strategies/volvo_strategy.py
```

**Expected Output:**
```
ğŸš€ Migrating data: 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 450k/1M [02:15<02:45, 3.2kdocs/s]
ğŸ“Š Migration Progress:
   â€¢ Documents migrated: 450,000
   â€¢ Rate: 3,200 docs/s
   â€¢ ETA: 2m 45s
   â€¢ RU consumption: 1,200 RU/s
```

**That's it!** ğŸ‰

---

## ğŸ“Š Performance Profiles

DataWorks comes with three optimized profiles for different use cases:

| Profile | Use Case | Performance | Memory | CPU |
|---------|----------|-------------|---------|-----|
| `dev` | Testing & Development | 1k docs/s | < 500MB | < 30% |
| `data-migration` | Production Migration | 4k-8k docs/s | < 2GB | < 60% |
| `data-ingest` | High-Speed Generation | 40k+ docs/s | < 4GB | < 80% |

**Change profile in `.env_local`:**
```env
FRAMEWORK_PROFILE=data-migration  # Choose your profile
```

---

## ğŸ”§ Common Use Cases

### 1. Migrate from Cosmos DB to Atlas

```bash
# Your Cosmos DB â†’ MongoDB Atlas migration
python flexible_migrate.py --strategy user_defined/strategies/volvo_strategy.py
```

**Real-world example:**
- **Source**: Cosmos DB with 2M documents (50GB)
- **Target**: MongoDB Atlas M30 cluster
- **Time**: ~45 minutes
- **Success rate**: 99.9%

### 2. Migrate from DynamoDB to MongoDB Atlas

```bash
# DynamoDB â†’ MongoDB Atlas migration
python flexible_migrate.py --strategy user_defined/strategies/volvo_strategy.py
```

**Configuration for DynamoDB:**
```env
# DynamoDB Local
GEN_DB_CONNECTION_STRING="dynamodb://localhost:8000"
GEN_DB_NAME=your-database
GEN_DB_COLLECTION=your-table

# AWS DynamoDB
GEN_DB_CONNECTION_STRING="dynamodb://aws"  # Uses AWS credentials
GEN_DB_NAME=your-database
GEN_DB_COLLECTION=your-table
```

### 3. Migrate from DocumentDB to MongoDB Atlas

```bash
# Amazon DocumentDB â†’ MongoDB Atlas migration
python flexible_migrate.py --strategy user_defined/strategies/volvo_strategy.py
```

**Configuration for DocumentDB:**
```env
GEN_DB_CONNECTION_STRING="mongodb://username:password@docdb-cluster.cluster-xyz.us-east-1.docdb.amazonaws.com:27017"
GEN_DB_NAME=your-database
GEN_DB_COLLECTION=your-collection
```

### 4. Generate Test Data

```bash
# Generate 1M documents for testing
python flexible_generator.py --source user_defined/templates/service_orders/service_order_template.json --total 1000000
```

**Performance metrics:**
- **Generation rate**: 15,000 docs/s
- **Memory usage**: 1.2GB
- **Time**: ~67 seconds

### 5. Custom Migration Strategy

```bash
# Use your own migration logic
python flexible_migrate.py --strategy my_custom_strategy.py
```

### 6. Index Management

```bash
# Disable indexes for faster migration
python flexible_migrate.py --strategy user_defined/strategies/volvo_strategy.py --disable-indexes

# Recreate indexes after migration
python flexible_migrate.py --strategy user_defined/strategies/volvo_strategy.py --create-indexes
```

---

## ğŸ“‹ Available Commands

### Data Generation

```bash
# List available generators
python flexible_generator.py --list-generators

# List JSON templates
python flexible_generator.py --list-templates

# Generate with Python generator
python flexible_generator.py --source user_defined/generators/volvo_generator.py --total 1000

# Generate with JSON template
python flexible_generator.py --source user_defined/templates/service_orders/service_order_template.json --total 1000
```

### Data Migration

```bash
# List available strategies
python flexible_migrate.py --list-strategies

# Standard migration
python flexible_migrate.py --strategy user_defined/strategies/volvo_strategy.py

# Force restart from beginning
python flexible_migrate.py --strategy user_defined/strategies/volvo_strategy.py --force-from-start

# Disable indexes for performance
python flexible_migrate.py --strategy user_defined/strategies/volvo_strategy.py --disable-indexes
```

---

## ğŸ—ï¸ Project Structure

```
dataworks/
â”œâ”€â”€ ğŸ“ framework/              # Core framework
â”‚   â”œâ”€â”€ core/                 # Database clients
â”‚   â”œâ”€â”€ config/               # Configuration system
â”‚   â”œâ”€â”€ generators/           # Data generation
â”‚   â”œâ”€â”€ migrations/           # Migration engine
â”‚   â””â”€â”€ monitoring/           # Performance tracking
â”œâ”€â”€ ğŸ“ user_defined/          # Your custom code
â”‚   â”œâ”€â”€ generators/           # Custom generators
â”‚   â”œâ”€â”€ strategies/           # Custom strategies
â”‚   â””â”€â”€ templates/           # JSON templates
â”œâ”€â”€ ğŸ”§ flexible_generator.py   # Data generation script
â”œâ”€â”€ ğŸ”§ flexible_migrate.py    # Migration script
â””â”€â”€ âš™ï¸ .env_local             # Your configuration
```

---

## ğŸ› ï¸ Configuration

### Database Connection Strings

**Cosmos DB (Source):**
```env
GEN_DB_CONNECTION_STRING="mongodb://account:password@account.mongo.cosmos.azure.com:10255/?ssl=true&replicaSet=globaldb"
```

**MongoDB Atlas (Target):**
```env
MIG_TARGET_DB_CONNECTION_STRING="mongodb+srv://username:password@cluster.mongodb.net/"
```

### Performance Tuning

```env
# Override profile settings
MIG_BATCH_SIZE=20000          # Documents per batch
GEN_BATCH_SIZE=50000          # Generation batch size
FRAMEWORK_WRITE_WORKERS=16    # Parallel workers
```

---

## ğŸ“ˆ Monitoring & Progress

DataWorks provides comprehensive real-time monitoring:

### ğŸ¯ **Enhanced Progress Tracking**

- **ğŸ“Š Progress bars** with document counts and rates
- **âš¡ Performance metrics** (docs/sec, RU consumption, memory usage)
- **ğŸ”„ Checkpoint recovery** (resume from interruptions)
- **ğŸ“ Detailed logging** for troubleshooting
- **â±ï¸ ETA calculations** for long-running operations
- **ğŸš¨ Error tracking** with retry statistics

### ğŸ“Š **Real-time Statistics**

```
ğŸš€ Migrating data: 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670k/1M [03:22<01:38, 3.3kdocs/s]
ğŸ“Š Live Statistics:
   â€¢ Documents migrated: 670,000
   â€¢ Current rate: 3,300 docs/s
   â€¢ Average rate: 3,100 docs/s
   â€¢ Peak rate: 4,200 docs/s
   â€¢ RU consumption: 1,150 RU/s
   â€¢ Memory usage: 1.8GB
   â€¢ ETA: 1m 38s
   â€¢ Errors: 0
   â€¢ Retries: 0
```

---

## ğŸš¨ Troubleshooting

### Common Issues

**Slow Performance:**
- Check network bandwidth
- Verify RU allocation in Cosmos DB
- Ensure Atlas cluster is appropriately sized

**Connection Errors:**
- Verify connection strings in `.env_local`
- Check network connectivity
- Ensure proper authentication

**Memory Issues:**
- Reduce batch size in configuration
- Increase system memory
- Monitor system resources

### Getting Help

1. **Check logs** for specific error messages
2. **Verify configuration** in `.env_local`
3. **Test data generation** with small amounts first
4. **Review performance metrics** in progress bars

---

## ğŸ“„ License

This project is provided as-is for enterprise data migration purposes.

---

**Ready to migrate?** Start with a small test: `python flexible_generator.py --source user_defined/templates/service_orders/service_order_template.json --total 5` ğŸš€